{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.parsing.preprocessing import remove_stopwords, stem_text\n",
    "from nltk.stem import WordNetLemmatizer as lemma #stemming or lemmatization or stopwords removal\n",
    "from itertools import compress\n",
    "import os\n",
    "import nltk\n",
    "import csv\n",
    "import re\n",
    "import string\n",
    "import pattern\n",
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CBOW Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-28 11:24:52,676 : INFO : loading Word2Vec object from word2vec.model\n",
      "2021-02-28 11:24:53,179 : INFO : loading wv recursively from word2vec.model.wv.* with mmap=None\n",
      "2021-02-28 11:24:53,180 : INFO : loading vectors from word2vec.model.wv.vectors.npy with mmap=None\n",
      "2021-02-28 11:24:53,256 : INFO : setting ignored attribute vectors_norm to None\n",
      "2021-02-28 11:24:53,257 : INFO : loading vocabulary recursively from word2vec.model.vocabulary.* with mmap=None\n",
      "2021-02-28 11:24:53,257 : INFO : loading trainables recursively from word2vec.model.trainables.* with mmap=None\n",
      "2021-02-28 11:24:53,258 : INFO : loading syn1neg from word2vec.model.trainables.syn1neg.npy with mmap=None\n",
      "2021-02-28 11:24:53,329 : INFO : setting ignored attribute cum_table to None\n",
      "2021-02-28 11:24:53,330 : INFO : loaded word2vec.model\n"
     ]
    }
   ],
   "source": [
    "# Import CBOW model that I trained\n",
    "model_CBOW = Word2Vec.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we us the Euclidean distance between word vectors to find similar words\n",
    "It seems reasonable results are produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similar words to hand\n",
      " [('hands', 0.6166726350784302), ('thumb', 0.5773354768753052), ('wrist', 0.5320491790771484), ('finger', 0.49942293763160706), ('fingertip', 0.4824220538139343), ('grip', 0.479486882686615), ('palms', 0.47491511702537537), ('handle', 0.47413989901542664), ('handed', 0.47237294912338257), ('ungloved', 0.4606072008609772)]\n",
      "similar words to clean\n",
      " [('cleaning', 0.6165425777435303), ('dirty', 0.5770803689956665), ('cleaned', 0.5731397867202759), ('wash', 0.5400612354278564), ('cleans', 0.5364762544631958), ('rinse', 0.5311837196350098), ('soiled', 0.5310670137405396), ('uncleaned', 0.5294914841651917), ('cool', 0.5272093415260315), ('cleansed', 0.5258091688156128)]\n",
      "similar words to space\n",
      " [('spaces', 0.751697301864624), ('interspace', 0.6127792000770569), ('cavity', 0.5913570523262024), ('chamber', 0.5684406161308289), ('compartment', 0.5631387829780579), ('void', 0.5578623414039612), ('gap', 0.5256147384643555), ('area', 0.5211427211761475), ('airspace', 0.4948205351829529), ('passageway', 0.491533100605011)]\n",
      "similar words to grass\n",
      " [('turf', 0.7565479278564453), ('lawn', 0.6663884520530701), ('lawns', 0.6645172238349915), ('vegetation', 0.6579054594039917), ('mulch', 0.6468108296394348), ('ophiuroides', 0.6322104930877686), ('clippings', 0.6279544234275818), ('barnyard', 0.6262950897216797), ('sprigs', 0.6200851798057556), ('bermuda', 0.6197203397750854)]\n",
      "similar words to ocean\n",
      " [('sea', 0.8328075408935547), ('oceanic', 0.6851358413696289), ('seabed', 0.6688036918640137), ('seafloor', 0.6681456565856934), ('coastal', 0.6415365934371948), ('oceans', 0.6337056159973145), ('estuary', 0.6285250186920166), ('river', 0.6222198605537415), ('inland', 0.6096713542938232), ('ship', 0.6001344919204712)]\n",
      "similar words to brain\n",
      " [('cerebral', 0.6645024418830872), ('myocardium', 0.655286431312561), ('neuronal', 0.6362521648406982), ('myocardial', 0.6350117921829224), ('neurological', 0.629993200302124), ('nerve', 0.6267679929733276), ('hippocampus', 0.6047471761703491), ('subcortical', 0.6038620471954346), ('cardiac', 0.5944594144821167), ('hippocampal', 0.5913131237030029)]\n",
      "similar words to eye\n",
      " [('eyes', 0.7660307884216309), ('eyeball', 0.7189425230026245), ('retina', 0.7163537740707397), ('ocular', 0.693799614906311), ('cornea', 0.6792399883270264), ('fundus', 0.6605297327041626), ('pupil', 0.5960537791252136), ('observer', 0.58548504114151), ('iris', 0.5786277055740356), ('retinal', 0.5672650933265686)]\n",
      "similar words to vacuum\n",
      " [('suction', 0.6749813556671143), ('vaccum', 0.5932492017745972), ('pressure', 0.5442273616790771), ('pressurized', 0.5129967927932739), ('evacuated', 0.5065582990646362), ('evacuating', 0.5038145184516907), ('vapor', 0.4969176948070526), ('plasma', 0.49454769492149353), ('subatmospheric', 0.492512583732605), ('gas', 0.47920387983322144)]\n",
      "similar words to network\n",
      " [('networks', 0.7538626194000244), ('lan', 0.7128121852874756), ('gateway', 0.709492564201355), ('internet', 0.7089822292327881), ('communications', 0.6779042482376099), ('networking', 0.6672261953353882), ('ip', 0.6648013591766357), ('server', 0.6518834829330444), ('router', 0.6511314511299133), ('service', 0.6457650661468506)]\n"
     ]
    }
   ],
   "source": [
    "w1 = \"hand\"\n",
    "print(\"similar words to\" + \" \" + w1 + \"\\n\", model_CBOW.wv.most_similar (positive=w1))\n",
    "\n",
    "w2 = \"clean\"\n",
    "print(\"similar words to\" + \" \" + w2 + \"\\n\", model_CBOW.wv.most_similar (positive=w2))\n",
    "\n",
    "w3 = \"space\"\n",
    "print(\"similar words to\" + \" \" + w3 + \"\\n\", model_CBOW.wv.most_similar (positive=w3))\n",
    "\n",
    "w4 = \"grass\"\n",
    "print(\"similar words to\" + \" \" + w4 + \"\\n\", model_CBOW.wv.most_similar (positive=w4))\n",
    "\n",
    "w5 = \"ocean\"\n",
    "print(\"similar words to\" + \" \" + w5 + \"\\n\", model_CBOW.wv.most_similar (positive=w5))\n",
    "\n",
    "w6 = \"brain\"\n",
    "print(\"similar words to\" + \" \" + w6 + \"\\n\", model_CBOW.wv.most_similar (positive=w6))\n",
    "\n",
    "w7 = \"eye\"\n",
    "print(\"similar words to\" + \" \" + w7 + \"\\n\", model_CBOW.wv.most_similar (positive=w7))\n",
    "\n",
    "w8 = \"vacuum\"\n",
    "print(\"similar words to\" + \" \" + w8 + \"\\n\", model_CBOW.wv.most_similar (positive=w8))\n",
    "\n",
    "w9 = \"network\"\n",
    "print(\"similar words to\" + \" \" + w9 + \"\\n\", model_CBOW.wv.most_similar (positive=w9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-28 11:50:02,571 : INFO : loading Word2VecKeyedVectors object from word2vec.wordvectors\n",
      "2021-02-28 11:50:03,141 : INFO : loading vectors from word2vec.wordvectors.vectors.npy with mmap=None\n",
      "2021-02-28 11:50:03,224 : INFO : setting ignored attribute vectors_norm to None\n",
      "2021-02-28 11:50:03,225 : INFO : loaded word2vec.wordvectors\n"
     ]
    }
   ],
   "source": [
    "# Get acess to word_vectors generated by skip-gram model\n",
    "word_vectors_CBOW = KeyedVectors.load('word2vec.wordvectors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.9738858 ,  3.8116271 , -0.10673207, -0.8873255 ,  1.3948431 ,\n",
       "        0.01506647, -0.36866117, -2.4929602 ,  0.04411354, -3.6139865 ,\n",
       "       -0.53421307,  0.96958256, -4.265465  , -1.3627622 ,  2.4924116 ,\n",
       "        1.1531667 , -0.5550834 , -1.2145711 ,  4.168068  , -2.644958  ,\n",
       "        1.7249612 , -3.035864  ,  0.9705034 ,  0.8611232 ,  2.7252595 ,\n",
       "        1.4907192 ,  1.9702926 ,  0.7301734 ,  1.2003199 , -1.1309636 ,\n",
       "        0.1287376 , -1.8611232 ,  2.57134   , -2.6713018 , -1.7605952 ,\n",
       "       -0.6703824 ,  1.0294801 ,  2.1466484 ,  1.2832888 ,  3.9520266 ,\n",
       "        2.097434  , -1.8139281 , -0.27315906,  3.0287864 , -2.6783013 ,\n",
       "        0.44741735,  5.0742674 , -1.0615453 , -0.834363  ,  1.5301282 ,\n",
       "        1.9985927 ,  2.2390718 , -1.592596  ,  0.37741378,  0.43900767,\n",
       "       -0.02169557,  3.3588276 ,  4.192112  ,  1.8434018 , -3.3749192 ,\n",
       "        3.059863  , -0.5627845 , -0.20609541, -5.4626517 , -3.8927288 ,\n",
       "       -3.558605  ,  0.46514493, -0.21348757,  0.12543829, -1.9553415 ,\n",
       "       -0.01314104,  1.3796593 , -0.20473957,  2.0377276 , -0.04517443,\n",
       "        1.9195298 ,  0.46487662,  3.438008  , -2.485024  ,  1.2017783 ,\n",
       "        3.8832202 ,  1.1708413 ,  5.242375  , -1.596542  ,  1.9296343 ,\n",
       "       -0.6452766 ,  1.0667174 , -0.14976299,  0.03816997, -1.5636417 ,\n",
       "        0.29761997, -1.9425694 ,  0.66866916, -2.3052378 , -2.6723309 ,\n",
       "       -0.5072625 ,  0.9211967 , -1.1041896 , -0.06018937, -3.6476068 ,\n",
       "        0.29417524,  2.1677647 ,  0.4748417 ,  1.568582  ,  1.5327637 ,\n",
       "       -1.08731   ,  1.6037856 ,  3.6435466 ,  1.7181166 , -0.43288502,\n",
       "        0.6651254 , -1.0398759 , -3.4041934 , -0.637555  , -1.6839476 ,\n",
       "       -0.7976897 ,  2.3014965 , -3.8219013 , -2.0787373 ,  0.14531994,\n",
       "       -2.5612524 ,  1.7953777 , -1.3041476 ,  4.086621  ,  0.55730313,\n",
       "       -3.6926146 ,  0.5189744 , -0.8192759 ,  1.7504395 ,  2.0188317 ,\n",
       "       -3.8399332 , -2.9991488 ,  0.25791174,  1.1194807 ,  0.43315974,\n",
       "       -0.6554222 , -1.8184814 ,  2.223805  ,  2.1509922 , -3.3325553 ,\n",
       "        0.23019004, -1.2434083 ,  2.8326359 ,  0.73834074, -0.8114285 ,\n",
       "       -1.4134173 ,  1.2866331 ,  0.08267812, -1.8923737 , -1.3279971 ,\n",
       "        3.725483  ,  2.892133  , -3.0973523 , -1.973509  , -0.9192446 ,\n",
       "        1.4047568 , -3.160984  ,  0.5183714 ,  2.9821675 ,  0.6959468 ,\n",
       "       -0.6339132 , -1.42495   ,  0.5094224 ,  0.5383623 ,  0.39470568,\n",
       "        0.87193614,  1.2492062 ,  2.0051632 ,  1.6536677 ,  2.4853163 ,\n",
       "       -2.4114714 ,  1.9029706 , -0.96825284, -2.1602724 ,  3.9257853 ,\n",
       "       -1.140784  ,  3.9592032 , -1.6639148 , -1.7107195 , -2.475679  ,\n",
       "        3.6339788 , -0.1701921 ,  1.2673767 , -1.1320562 , -0.75193226,\n",
       "       -0.3500936 , -3.3521824 , -1.6650404 ,  4.370727  , -2.282052  ,\n",
       "       -2.9726195 ,  3.441102  , -0.3689238 ,  0.7655682 ,  0.9790604 ,\n",
       "        0.87036586,  1.8457426 , -0.8448529 ,  0.56367946,  2.1092906 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors_CBOW['eye'] # word vector for 'eye'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skip-gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-28 11:20:41,316 : INFO : loading Word2Vec object from word2vec_sg.model\n",
      "2021-02-28 11:20:41,706 : INFO : loading wv recursively from word2vec_sg.model.wv.* with mmap=None\n",
      "2021-02-28 11:20:41,707 : INFO : loading vectors from word2vec_sg.model.wv.vectors.npy with mmap=None\n",
      "2021-02-28 11:20:41,795 : INFO : setting ignored attribute vectors_norm to None\n",
      "2021-02-28 11:20:41,795 : INFO : loading vocabulary recursively from word2vec_sg.model.vocabulary.* with mmap=None\n",
      "2021-02-28 11:20:41,796 : INFO : loading trainables recursively from word2vec_sg.model.trainables.* with mmap=None\n",
      "2021-02-28 11:20:41,798 : INFO : loading syn1neg from word2vec_sg.model.trainables.syn1neg.npy with mmap=None\n",
      "2021-02-28 11:20:41,868 : INFO : setting ignored attribute cum_table to None\n",
      "2021-02-28 11:20:41,870 : INFO : loaded word2vec_sg.model\n"
     ]
    }
   ],
   "source": [
    "# Import Skip-gram model that I trained\n",
    "model_sg = Word2Vec.load(\"word2vec_sg.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we us the Euclidean distance between word vectors to find similar words\n",
    "It seems reasonable results are produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similar words to hand\n",
      " [('hands', 0.666816771030426), ('grip', 0.6162362694740295), ('handheld', 0.5833435654640198), ('held', 0.5777618288993835), ('thumb', 0.5683989524841309), ('finger', 0.5674130916595459), ('fingertip', 0.5662369728088379), ('wrist', 0.5559874176979065), ('glove', 0.5510510802268982), ('handle', 0.5471358299255371)]\n",
      "similar words to clean\n",
      " [('cleaned', 0.7214415073394775), ('cleaning', 0.6857302784919739), ('dirty', 0.6056607365608215), ('cleans', 0.5931688547134399), ('cleanse', 0.5638104677200317), ('cleaner', 0.5545836687088013), ('disinfect', 0.5516268014907837), ('scrubbed', 0.5446197390556335), ('soiled', 0.538492739200592), ('sanitize', 0.5377720594406128)]\n",
      "similar words to space\n",
      " [('spaces', 0.7825511693954468), ('partition', 0.5470077991485596), ('cavity', 0.5142579674720764), ('void', 0.5132923722267151), ('accommodation', 0.5112019181251526), ('workspace', 0.5025098323822021), ('inside', 0.498166561126709), ('partitions', 0.49671226739883423), ('gap', 0.4830506443977356), ('slot', 0.4824589490890503)]\n",
      "similar words to grass\n",
      " [('turf', 0.757792055606842), ('lawn', 0.7408095598220825), ('mulch', 0.7095460891723633), ('clippings', 0.7085317373275757), ('vegetation', 0.7040784358978271), ('mowing', 0.6913439035415649), ('mulching', 0.6605969667434692), ('mower', 0.6520372629165649), ('weed', 0.6388605833053589), ('lawns', 0.6275840401649475)]\n",
      "similar words to ocean\n",
      " [('sea', 0.8188051581382751), ('seabed', 0.7292262315750122), ('seafloor', 0.7203499674797058), ('offshore', 0.6848180294036865), ('river', 0.6737468838691711), ('oceanic', 0.6656750440597534), ('moored', 0.6502468585968018), ('ship', 0.6439331769943237), ('buoy', 0.642741858959198), ('coastal', 0.6348066329956055)]\n",
      "similar words to brain\n",
      " [('cerebral', 0.7809474468231201), ('myocardial', 0.7458490133285522), ('neurological', 0.7089080214500427), ('nerve', 0.7044943571090698), ('myocardium', 0.6921192407608032), ('ischemic', 0.6906895041465759), ('nerves', 0.6824162006378174), ('ischemia', 0.6759458780288696), ('cardiac', 0.6614117622375488), ('neuronal', 0.6598320007324219)]\n",
      "similar words to eye\n",
      " [('eyes', 0.8023295998573303), ('ocular', 0.7203682661056519), ('eyeball', 0.7054115533828735), ('retina', 0.6774422526359558), ('cornea', 0.6543327569961548), ('sclera', 0.6167570352554321), ('fundus', 0.6149924397468567), ('eyelid', 0.6007823944091797), ('corneal', 0.5859100818634033), ('anterior', 0.5739483833312988)]\n",
      "similar words to vacuum\n",
      " [('suction', 0.705642819404602), ('subatmospheric', 0.6161016225814819), ('evacuated', 0.612635612487793), ('evacuating', 0.6018824577331543), ('vaccum', 0.5907180309295654), ('pressure', 0.5764195322990417), ('chamber', 0.5627647638320923), ('cleaner', 0.5611953735351562), ('canister', 0.5483585596084595), ('vacuuming', 0.5364481806755066)]\n",
      "similar words to network\n",
      " [('networks', 0.8499081134796143), ('gateway', 0.7442525625228882), ('networking', 0.7104737758636475), ('internet', 0.6981134414672852), ('peer', 0.685767650604248), ('router', 0.6834752559661865), ('lan', 0.6818010807037354), ('connectivity', 0.6749587059020996), ('communications', 0.6709034442901611), ('infrastructure', 0.667117714881897)]\n"
     ]
    }
   ],
   "source": [
    "w1 = \"hand\"\n",
    "print(\"similar words to\" + \" \" + w1 + \"\\n\", model_sg.wv.most_similar (positive=w1))\n",
    "\n",
    "w2 = \"clean\"\n",
    "print(\"similar words to\" + \" \" + w2 + \"\\n\", model_sg.wv.most_similar (positive=w2))\n",
    "\n",
    "w3 = \"space\"\n",
    "print(\"similar words to\" + \" \" + w3 + \"\\n\", model_sg.wv.most_similar (positive=w3))\n",
    "\n",
    "w4 = \"grass\"\n",
    "print(\"similar words to\" + \" \" + w4 + \"\\n\", model_sg.wv.most_similar (positive=w4))\n",
    "\n",
    "w5 = \"ocean\"\n",
    "print(\"similar words to\" + \" \" + w5 + \"\\n\", model_sg.wv.most_similar (positive=w5))\n",
    "\n",
    "w6 = \"brain\"\n",
    "print(\"similar words to\" + \" \" + w6 + \"\\n\", model_sg.wv.most_similar (positive=w6))\n",
    "\n",
    "w7 = \"eye\"\n",
    "print(\"similar words to\" + \" \" + w7 + \"\\n\", model_sg.wv.most_similar (positive=w7))\n",
    "\n",
    "w8 = \"vacuum\"\n",
    "print(\"similar words to\" + \" \" + w8 + \"\\n\", model_sg.wv.most_similar (positive=w8))\n",
    "\n",
    "w9 = \"network\"\n",
    "print(\"similar words to\" + \" \" + w9 + \"\\n\", model_sg.wv.most_similar (positive=w9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-28 14:23:12,396 : INFO : loading Word2VecKeyedVectors object from word2vec_sg.wordvectors\n",
      "2021-02-28 14:23:12,740 : INFO : loading vectors from word2vec_sg.wordvectors.vectors.npy with mmap=None\n",
      "2021-02-28 14:23:12,909 : INFO : setting ignored attribute vectors_norm to None\n",
      "2021-02-28 14:23:12,910 : INFO : loaded word2vec_sg.wordvectors\n"
     ]
    }
   ],
   "source": [
    "# Get acess to word_vectors generated by skip-gram model\n",
    "word_vectors_sg = KeyedVectors.load('word2vec_sg.wordvectors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.51827055, -0.6340611 , -0.25729594,  0.25179762, -0.27625433,\n",
       "        0.05386381, -0.40232638,  0.08906189, -0.3361348 , -0.4503918 ,\n",
       "       -0.07894787, -0.41111544, -0.09601761,  0.36381373, -0.04692127,\n",
       "       -0.31368914,  0.00280539,  0.17267376,  0.03954573, -0.42875382,\n",
       "       -0.5196362 , -0.20841406, -0.07160375, -0.4397674 ,  0.01639264,\n",
       "        0.2449794 ,  0.2810396 , -0.26302823, -0.2970647 , -0.19021453,\n",
       "       -0.16284542,  0.07553928,  0.01730639,  0.3114152 ,  0.26547807,\n",
       "        0.28288028, -0.34840724, -0.18200034, -0.23350362,  0.24331962,\n",
       "       -0.07442116,  0.44617212,  0.12168942, -0.03515651, -0.39623487,\n",
       "       -0.24214469, -0.23039289,  0.03672168,  0.13092375,  0.02749238,\n",
       "       -0.01736509, -0.06532747, -0.48730186, -0.16251104, -0.14337051,\n",
       "       -0.15168759,  0.23323321,  0.13998765, -0.14969876, -0.2955798 ,\n",
       "        0.51090825, -0.27288398, -0.19559474, -0.23807862,  0.04938724,\n",
       "        0.33292067,  0.09851936, -0.12001956,  0.15794076,  0.39280018,\n",
       "        0.08662169, -0.09692302, -0.11730903, -0.34326878, -0.28366944,\n",
       "       -0.04905876,  0.11752815,  0.61319363, -0.45469546,  0.22430998,\n",
       "        0.08152524,  0.10609284,  0.29296818,  0.03245731, -0.04306068,\n",
       "       -0.20438194,  0.27970257,  0.09635213,  0.05559556,  0.24950309,\n",
       "       -0.06167537, -0.02172125, -0.18816169, -0.2446278 , -0.04560581,\n",
       "        0.06548295, -0.29817292,  0.03562543, -0.10763483, -0.17814462,\n",
       "        0.34808394, -0.04993422, -0.808261  ,  0.5381839 , -0.2526987 ,\n",
       "       -0.08232617,  0.12784068,  0.17200728,  0.0106728 ,  0.4508421 ,\n",
       "        0.24696136, -0.11394443, -0.09537046, -0.11604951,  0.01073796,\n",
       "        0.2844771 , -0.11683468,  0.02956189, -0.01409654, -0.32024947,\n",
       "       -0.5566018 , -0.37117222,  0.20680827, -0.07760268, -0.27107516,\n",
       "        0.29303282, -0.20925467, -0.02110213,  0.03975891, -0.25972798,\n",
       "        0.48359343, -0.05639221,  0.64971596,  0.3488773 ,  0.15167712,\n",
       "        0.2687499 ,  0.53772867,  0.3241868 , -0.38547757,  0.07561409,\n",
       "        0.53622174, -0.00155652, -0.06220272, -0.5250426 , -0.2731774 ,\n",
       "        0.2383901 , -0.4661885 ,  0.05418963, -0.41294912,  0.48994797,\n",
       "        0.19233145,  0.01171964, -0.14129218, -0.3651849 , -0.20972613,\n",
       "        0.5458153 ,  0.16063893,  0.42074084,  0.2161419 , -0.3147845 ,\n",
       "       -0.24766591, -0.3791476 ,  0.64500844, -0.273066  , -0.3247741 ,\n",
       "        0.21967825,  0.39588544, -0.04607301, -0.5546354 , -0.09701508,\n",
       "       -0.24798605,  0.03929933, -0.31956288,  0.1711532 , -0.36263552,\n",
       "       -0.5651237 , -0.11416472,  0.08989864,  0.13044815,  0.40178934,\n",
       "        0.33712593, -0.32125708, -0.37974316, -0.11685003,  0.16652158,\n",
       "       -0.06514511,  0.2165367 , -0.05361785,  0.19090466,  0.05217261,\n",
       "        0.09660262, -0.08205466, -0.12115404,  0.10345038, -0.11951353,\n",
       "       -0.30178759, -0.1634682 , -0.09488526,  0.12484206, -0.36760342],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors_sg['eye']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate matrix representation from title+abstraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"patent_abstract_title.csv\"\n",
    "\n",
    "# We take first 11 documents to develop a procedure that later will be used to feed data to the final models\n",
    "lines = []\n",
    "\n",
    "with open(filename, \"r\", encoding='cp932', errors='ignore') as patent_abstract_title:\n",
    "    reader = csv.DictReader(patent_abstract_title)\n",
    "    counter = 0\n",
    "    for row in reader:\n",
    "        if row[\"abstract\"] == 'NULL':\n",
    "            line = re.sub('[^a-zA-Z0-9]', ' ', row[\"title\"]) # remove non-letters and non-numbers\n",
    "            lines.append(utils.simple_preprocess(line)) # tokenization\n",
    "        else:\n",
    "            line = re.sub('[^a-zA-Z0-9]', ' ', row[\"title\"] + ' ' + row[\"abstract\"]) # remove non-letters and non-numbers\n",
    "            lines.append(utils.simple_preprocess(line)) # tokenization\n",
    "        counter += 1\n",
    "        if counter > 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['coherent',\n",
       " 'ladar',\n",
       " 'using',\n",
       " 'intra',\n",
       " 'pixel',\n",
       " 'quadrature',\n",
       " 'detection',\n",
       " 'frequency',\n",
       " 'modulated',\n",
       " 'coherent',\n",
       " 'laser',\n",
       " 'detection',\n",
       " 'and',\n",
       " 'ranging',\n",
       " 'system',\n",
       " 'includes',\n",
       " 'read',\n",
       " 'out',\n",
       " 'integrated',\n",
       " 'circuit',\n",
       " 'formed',\n",
       " 'with',\n",
       " 'two',\n",
       " 'dimensional',\n",
       " 'array',\n",
       " 'of',\n",
       " 'detector',\n",
       " 'elements',\n",
       " 'each',\n",
       " 'including',\n",
       " 'photosensitive',\n",
       " 'region',\n",
       " 'receiving',\n",
       " 'both',\n",
       " 'return',\n",
       " 'light',\n",
       " 'reflected',\n",
       " 'from',\n",
       " 'target',\n",
       " 'and',\n",
       " 'light',\n",
       " 'from',\n",
       " 'local',\n",
       " 'oscillator',\n",
       " 'and',\n",
       " 'local',\n",
       " 'processing',\n",
       " 'circuitry',\n",
       " 'sampling',\n",
       " 'the',\n",
       " 'output',\n",
       " 'of',\n",
       " 'the',\n",
       " 'photosensitive',\n",
       " 'region',\n",
       " 'four',\n",
       " 'times',\n",
       " 'during',\n",
       " 'each',\n",
       " 'sample',\n",
       " 'period',\n",
       " 'clock',\n",
       " 'cycle',\n",
       " 'to',\n",
       " 'obtain',\n",
       " 'quadrature',\n",
       " 'components',\n",
       " 'data',\n",
       " 'bus',\n",
       " 'coupled',\n",
       " 'to',\n",
       " 'one',\n",
       " 'or',\n",
       " 'more',\n",
       " 'outputs',\n",
       " 'of',\n",
       " 'each',\n",
       " 'of',\n",
       " 'the',\n",
       " 'detector',\n",
       " 'elements',\n",
       " 'receives',\n",
       " 'the',\n",
       " 'quadrature',\n",
       " 'components',\n",
       " 'from',\n",
       " 'each',\n",
       " 'of',\n",
       " 'the',\n",
       " 'detector',\n",
       " 'elements',\n",
       " 'for',\n",
       " 'each',\n",
       " 'sample',\n",
       " 'period',\n",
       " 'and',\n",
       " 'serializes',\n",
       " 'the',\n",
       " 'received',\n",
       " 'quadrature',\n",
       " 'components',\n",
       " 'processor',\n",
       " 'coupled',\n",
       " 'to',\n",
       " 'the',\n",
       " 'data',\n",
       " 'bus',\n",
       " 'receives',\n",
       " 'the',\n",
       " 'serialized',\n",
       " 'quadrature',\n",
       " 'components',\n",
       " 'and',\n",
       " 'determines',\n",
       " 'an',\n",
       " 'amplitude',\n",
       " 'and',\n",
       " 'phase',\n",
       " 'for',\n",
       " 'at',\n",
       " 'least',\n",
       " 'one',\n",
       " 'interfering',\n",
       " 'frequency',\n",
       " 'corresponding',\n",
       " 'to',\n",
       " 'interference',\n",
       " 'between',\n",
       " 'the',\n",
       " 'return',\n",
       " 'light',\n",
       " 'and',\n",
       " 'the',\n",
       " 'local',\n",
       " 'oscillator',\n",
       " 'light',\n",
       " 'using',\n",
       " 'the',\n",
       " 'quadrature',\n",
       " 'components']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When we trained skip-gram we instructed the model to ignore infrequent words, we can use the following technique to\n",
    "#remove tokens that are not in the vocabulary when querying the word vectors\n",
    "print(len(lines[0])) #140 words\n",
    "lines[0] #first title_abstraction tokenized\n",
    "bool_list = [word in word_vectors_sg for word in lines[0]]\n",
    "bool_list\n",
    "res = list(compress(lines[0], bool_list))\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.07071864 -0.12117358 -0.02185552 ...  0.64721555  0.21990864\n",
      "  -0.05994103]\n",
      " [-0.80604136 -0.574496    0.09994247 ...  0.4465879   0.54236925\n",
      "  -0.45809165]\n",
      " [-0.19696032 -0.13701858  0.47668064 ...  0.00276972 -0.02947054\n",
      "   0.1093371 ]\n",
      " ...\n",
      " [-0.23305248 -0.11825893 -0.06362902 ... -0.0623644  -0.07161056\n",
      "  -0.15829077]\n",
      " [-0.13485767 -0.25736636  0.2320168  ...  0.5507349  -0.36124986\n",
      "   0.01316689]\n",
      " [-0.05706431 -0.06571136  0.14171483 ... -0.29895943  0.15447804\n",
      "   0.04359902]]\n"
     ]
    }
   ],
   "source": [
    "doc_matrix = word_vectors_sg[lines[0]] #This creates the matrix representation of above document\n",
    "print(doc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 200)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_matrix.shape # 140 200-dimensional word vectors vertically stacked, as desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix generating function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_generator(filename, num_doc):\n",
    "    '''\n",
    "    Input:\n",
    "    filename: name of the csv file we want to read data from\n",
    "    num_doc: number of document matrices we want to produce\n",
    "    \n",
    "    Output:\n",
    "    print of matrix representations of num_doc number of title+abstraction texts\n",
    "    '''\n",
    "    with open(filename, \"r\", encoding='cp932', errors='ignore') as patent_abstract_title:\n",
    "        reader = csv.DictReader(patent_abstract_title)\n",
    "        counter = 0\n",
    "        for row in reader:\n",
    "            if row[\"abstract\"] == 'NULL':\n",
    "                line = re.sub('[^a-zA-Z0-9]', ' ', row[\"title\"]) # remove non-letters and non-numbers\n",
    "                matrix = word_vectors_sg[utils.simple_preprocess(line)] # generate document matrix representation from tokens\n",
    "                print(f\"{counter + 1}st document matrix\",  f\"with shape {matrix.shape}: \\n\", matrix)\n",
    "            else:\n",
    "                line = re.sub('[^a-zA-Z0-9]', ' ', row[\"title\"] + ' ' + row[\"abstract\"]) # remove non-letters and non-numbers\n",
    "                matrix = word_vectors_sg[utils.simple_preprocess(line)] # generate document matrix representation from tokens\n",
    "                print(f\"{counter + 1}st document matrix\", f\"with shape {matrix.shape}: \\n\", matrix)\n",
    "            counter += 1\n",
    "            if counter > num_doc - 1:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st document matrix with shape (140, 200): \n",
      " [[-0.07071864 -0.12117358 -0.02185552 ...  0.64721555  0.21990864\n",
      "  -0.05994103]\n",
      " [-0.80604136 -0.574496    0.09994247 ...  0.4465879   0.54236925\n",
      "  -0.45809165]\n",
      " [-0.19696032 -0.13701858  0.47668064 ...  0.00276972 -0.02947054\n",
      "   0.1093371 ]\n",
      " ...\n",
      " [-0.23305248 -0.11825893 -0.06362902 ... -0.0623644  -0.07161056\n",
      "  -0.15829077]\n",
      " [-0.13485767 -0.25736636  0.2320168  ...  0.5507349  -0.36124986\n",
      "   0.01316689]\n",
      " [-0.05706431 -0.06571136  0.14171483 ... -0.29895943  0.15447804\n",
      "   0.04359902]]\n",
      "2st document matrix with shape (125, 200): \n",
      " [[-0.32603273 -0.04384432  0.13878149 ...  0.4449745   0.16914774\n",
      "  -0.33136952]\n",
      " [-0.443551   -0.22337495  0.4292946  ...  0.20105986 -0.05108025\n",
      "   0.11384816]\n",
      " [-0.25388038 -0.26835048  0.04451463 ...  0.15914683  0.58927596\n",
      "  -0.18065932]\n",
      " ...\n",
      " [-0.15530425 -0.4123554   0.28184384 ... -0.3144143  -0.2930772\n",
      "   0.33332857]\n",
      " [ 0.01849854 -0.0897783   0.2838198  ... -0.11331803  0.24042666\n",
      "  -0.12471124]\n",
      " [-0.43674237  0.1935006   0.3595624  ...  0.19922063 -0.07207747\n",
      "  -0.05610256]]\n",
      "3st document matrix with shape (125, 200): \n",
      " [[ 0.08978475 -0.3919285   0.22259398 ... -0.1844055  -0.13238774\n",
      "   0.02305178]\n",
      " [-0.05382434 -0.255958    0.17951462 ...  0.01161685  0.10536007\n",
      "  -0.18649836]\n",
      " [-0.07426226 -0.17417938  0.60798705 ...  0.00940921 -0.17738467\n",
      "   0.0478581 ]\n",
      " ...\n",
      " [-0.01412711 -0.28715223 -0.28075534 ...  0.17694806  0.30885607\n",
      "   0.0364277 ]\n",
      " [-0.4070618  -0.06888704  0.40990433 ... -0.1967404   0.43643802\n",
      "   0.0791247 ]\n",
      " [-0.1751378  -0.3247248  -0.02089467 ...  0.1500209   0.39019904\n",
      "   0.02233443]]\n",
      "4st document matrix with shape (129, 200): \n",
      " [[ 0.08978475 -0.3919285   0.22259398 ... -0.1844055  -0.13238774\n",
      "   0.02305178]\n",
      " [-0.05382434 -0.255958    0.17951462 ...  0.01161685  0.10536007\n",
      "  -0.18649836]\n",
      " [-0.15530425 -0.4123554   0.28184384 ... -0.3144143  -0.2930772\n",
      "   0.33332857]\n",
      " ...\n",
      " [-0.04517411 -0.17387976  0.29694694 ...  0.00849846 -0.0613431\n",
      "  -0.15562445]\n",
      " [-0.23305248 -0.11825893 -0.06362902 ... -0.0623644  -0.07161056\n",
      "  -0.15829077]\n",
      " [-0.16114266  0.08152498  0.04711492 ...  0.4233468   0.44052333\n",
      "  -0.18968847]]\n",
      "5st document matrix with shape (110, 200): \n",
      " [[-0.21475576 -0.3910135   0.34983516 ... -0.37754607  0.07464993\n",
      "   0.0528815 ]\n",
      " [-0.06112558 -0.1571497  -0.00485985 ...  0.06934264 -0.0104467\n",
      "  -0.18207476]\n",
      " [ 0.046508   -0.3911931   0.00378988 ...  0.00891576 -0.14504145\n",
      "  -0.1428865 ]\n",
      " ...\n",
      " [ 0.38134122 -0.2209042   0.5418617  ... -0.08760712 -0.18430953\n",
      "   0.07463331]\n",
      " [-0.24607965 -0.14490251  0.00470321 ...  0.09955952 -0.00328919\n",
      "  -0.05138823]\n",
      " [-0.4460963  -0.01830433 -0.04726203 ...  0.5325246   0.03750065\n",
      "  -0.39381117]]\n",
      "6st document matrix with shape (146, 200): \n",
      " [[-0.16309477 -0.5706757   0.23315756 ... -0.05190176  0.10942019\n",
      "   0.02419535]\n",
      " [-0.32468593 -0.0757689   0.2857863  ...  0.09602646  0.56520945\n",
      "  -0.03461375]\n",
      " [-0.26713026 -0.1840275   0.57185465 ... -0.04818388 -0.09282177\n",
      "   0.04872648]\n",
      " ...\n",
      " [-0.24607965 -0.14490251  0.00470321 ...  0.09955952 -0.00328919\n",
      "  -0.05138823]\n",
      " [-0.01182528 -0.17803599 -0.1890213  ... -0.09362734  0.00191628\n",
      "  -0.14197487]\n",
      " [-0.05650269 -0.19425078  0.18466546 ... -0.19309413  0.24625066\n",
      "   0.18231945]]\n",
      "7st document matrix with shape (128, 200): \n",
      " [[-0.07315645 -0.46496072  0.40436596 ...  0.4037456   0.14467815\n",
      "   0.2181137 ]\n",
      " [-0.29435298 -0.31012782  0.32481584 ...  0.48173174  0.00522928\n",
      "   0.18179467]\n",
      " [-0.18190773 -0.2214879   0.19465846 ...  0.2397936   0.35134333\n",
      "  -0.04262179]\n",
      " ...\n",
      " [-0.06112558 -0.1571497  -0.00485985 ...  0.06934264 -0.0104467\n",
      "  -0.18207476]\n",
      " [-0.23305248 -0.11825893 -0.06362902 ... -0.0623644  -0.07161056\n",
      "  -0.15829077]\n",
      " [-0.29435298 -0.31012782  0.32481584 ...  0.48173174  0.00522928\n",
      "   0.18179467]]\n",
      "8st document matrix with shape (114, 200): \n",
      " [[ 0.16055879 -0.05256291  0.02081507 ... -0.2215267   0.00748727\n",
      "   0.51540416]\n",
      " [-0.1473403   0.32724446  0.03728327 ...  0.05892764  0.39639324\n",
      "   0.10298391]\n",
      " [-0.35096267 -0.25659135  0.14049171 ...  0.25157133  0.03144673\n",
      "   0.2504847 ]\n",
      " ...\n",
      " [-0.23305248 -0.11825893 -0.06362902 ... -0.0623644  -0.07161056\n",
      "  -0.15829077]\n",
      " [-0.3079593  -0.05712321  0.09394234 ... -0.0656926   0.38312882\n",
      "  -0.40118808]\n",
      " [ 0.1230972  -0.15605123  0.12465291 ... -0.15091512  0.3539848\n",
      "  -0.16821818]]\n",
      "9st document matrix with shape (59, 200): \n",
      " [[-0.24878186 -0.31893012  0.96264976 ... -0.01211249  0.35793445\n",
      "   0.11392687]\n",
      " [-0.29435298 -0.31012782  0.32481584 ...  0.48173174  0.00522928\n",
      "   0.18179467]\n",
      " [-0.18999952 -0.08108239  0.18358874 ...  0.03190745  0.01068125\n",
      "  -0.16805337]\n",
      " ...\n",
      " [-0.24878186 -0.31893012  0.96264976 ... -0.01211249  0.35793445\n",
      "   0.11392687]\n",
      " [ 0.05250216 -0.14224331  0.09114245 ... -0.23771608 -0.15523693\n",
      "  -0.19814141]\n",
      " [ 0.16181287 -0.23744376  0.8724283  ...  0.05114645  0.18671605\n",
      "  -0.20945007]]\n",
      "10st document matrix with shape (123, 200): \n",
      " [[ 0.03078464 -0.1542045   0.20486292 ...  0.3739609   0.31887484\n",
      "  -0.12651907]\n",
      " [-0.24220124 -0.08245192 -0.02664682 ... -0.07881503  0.4207498\n",
      "  -0.3503632 ]\n",
      " [-0.05382434 -0.255958    0.17951462 ...  0.01161685  0.10536007\n",
      "  -0.18649836]\n",
      " ...\n",
      " [-0.6401876  -0.36428162  0.04096473 ... -0.08672091  0.07814743\n",
      "  -0.441353  ]\n",
      " [-0.5508     -0.13594612  0.179089   ...  0.12945029  0.12475909\n",
      "  -0.20331962]\n",
      " [-0.36801305 -0.23391385  0.45784628 ... -0.17845245  0.2407985\n",
      "   0.3630682 ]]\n"
     ]
    }
   ],
   "source": [
    "matrix_generator(filename, num_doc = 10) #This kind of matrix is suitable for CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
